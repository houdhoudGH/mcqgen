{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9ccafab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ffe76f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7b8a27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv(\"HUGGING_FACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "8c3f531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "aa3d1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"conversational\", \n",
    "    provider=\"fireworks-ai\",\n",
    "    max_new_tokens=512\n",
    ")\n",
    "chat = ChatHuggingFace(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5759d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "31fe3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = SystemMessage(content=\"/no_think Answer very briefly and do not explain your reasoning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "2b610f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "39dd8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_QUIZ_NEW = \"\"\"\\\n",
    "{system_msg}\n",
    "Context: {text}\n",
    "Your task is to write exactly {number} multiple-choice questions based on the above content. The questions should be appropriate for {subject} students and written in a {difficulty} difficulty.\n",
    "Return ONLY a JSON object matching the format shown in RESPONSE_JSON below. Do not include any extra explanation.\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b91fddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_prompt_new = PromptTemplate(\n",
    "    input_variables=[\"system_msg\", \"text\", \"number\", \"subject\", \"difficulty\", \"response_json\"],\n",
    "    template=TEMPLATE_QUIZ_NEW,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e6946a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=chat, prompt=quiz_prompt_new, output_key=\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1ddce5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_REVIEW_NEW = \"\"\"\\\n",
    "{system_msg}\n",
    "Below is a quiz for {subject} students. Review its difficulty in no more than 50 words. If any question is not suitable, rewrite only the problem parts in a suitable difficulty.\n",
    "Quiz:\n",
    "{quiz}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f224b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_prompt_new = PromptTemplate(\n",
    "    input_variables=[\"system_msg\", \"subject\", \"quiz\"],\n",
    "    template=TEMPLATE_REVIEW_NEW,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "760a21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=chat, prompt=review_prompt_new, output_key=\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "30c80b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=[\"system_msg\", \"text\", \"number\", \"subject\", \"difficulty\",\"response_json\"],\n",
    "    output_variables=[\"quiz\", \"review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "3f0ecf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "7c210f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ac2f8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data.txt\", 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "2a83530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    \"system_msg\": system_msg.content,\n",
    "    \"text\": TEXT,\n",
    "    \"number\":\"2\",\n",
    "    \"subject\":\"Generative AI\",\n",
    "    \"difficulty\":\"intermediate\",\n",
    "    \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "19f60123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=combined_chain(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "20b2fe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"1\": {\"mcq\": \"What is the primary difference between Generative AI and traditional AI systems?\", \"options\": {\"a\": \"Generative AI can only analyze data, while traditional AI can classify data\", \"b\": \"Generative AI can create new content, while traditional AI can only analyze data\", \"c\": \"Generative AI is faster than traditional AI, while traditional AI is more accurate\", \"d\": \"Generative AI is only used for image generation, while traditional AI is used for text classification\"}, \"correct\": \"b\"},\n",
      "\"2\": {\"mcq\": \"Which Generative AI model is known for its ability to generate realistic images and videos?\", \"options\": {\"a\": \"Transformers\", \"b\": \"Diffusion Models\", \"c\": \"Variational Autoencoders (VAEs)\", \"d\": \"Generative Adversarial Networks (GANs)\"}, \"correct\": \"d\"}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response[\"quiz\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "29e9d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "1146b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5bb2c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "98527618",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "275cea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"quiz.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
